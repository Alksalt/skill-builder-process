{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8476d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "0.23.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics import Accuracy, F1Score, Recall, Precision, ConfusionMatrix\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "from helper_functions import print_train_time\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85b43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=2),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "#Setup training data\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform,\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff457849",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "\n",
    "NUM_CLASSES = len(class_names)\n",
    "#Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b1ab5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d7205b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '9')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774553a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168e31b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available()\n",
    "                      else \"cuda\" if torch.cuda.is_available()\n",
    "                      else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a470e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training func\n",
    "def train_step(model:torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device | str = 'cpu',\n",
    "               task: str = \"multiclass\",\n",
    "               num_classes = None,\n",
    "               scheduler: torch.optim.lr_scheduler._LRScheduler | None  = None) -> tuple:\n",
    "    \"\"\"Performs a training with model trying to learn on data_loader\"\"\"\n",
    "    #Creating training and test loop\n",
    "    model.train()\n",
    "    acc_metric = Accuracy(task=task, num_classes=num_classes).to(device)\n",
    "    total_loss, total_n  = 0, 0\n",
    "\n",
    "    # initializing from optimizer before any steps\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    for X, y in tqdm(data_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        #1. Forward pass\n",
    "        logits = model(X)\n",
    "\n",
    "        #2. Calculate loss (per batch)\n",
    "        batch_loss = loss_fn(logits, y)\n",
    "\n",
    "        #Calc total loss and n(number of sample(batch))\n",
    "        n = y.size(0)\n",
    "        total_loss += batch_loss.item() * n # accumulate train loss\n",
    "        total_n += n\n",
    "\n",
    "        #acc\n",
    "        acc_metric.update(logits, y)\n",
    "\n",
    "        #3 three steps\n",
    "        optimizer.zero_grad(set_to_none=True); batch_loss.backward(); optimizer.step()\n",
    "\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "\n",
    "\n",
    "    # Scale loss and acc to find the average loss/acc per batch\n",
    "    avg_loss = total_loss / total_n\n",
    "    avg_acc = acc_metric.compute().item()\n",
    "    print(f\"Train loss: {avg_loss:.5f} | Train accuracy: {avg_acc * 100:.2f}% | lr: {current_lr}\")\n",
    "    return avg_loss, avg_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb0f04e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing func\n",
    "def test_step(model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              device: torch.device | str = \"cpu\",\n",
    "              task: str = \"multiclass\",\n",
    "              num_classes = None) -> tuple:\n",
    "    \"\"\"Returns a tuple that contains avg_loss, avg_acc\"\"\"\n",
    "    acc_metric = Accuracy(task=task, num_classes=num_classes).to(device)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_n = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(data_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Make predictions\n",
    "            logits = model(X)\n",
    "            batch_loss = loss_fn(logits, y)\n",
    "\n",
    "            n = y.size(0)\n",
    "            total_loss += batch_loss.item() * n\n",
    "            total_n += n\n",
    "\n",
    "            acc_metric.update(logits, y)\n",
    "    # Scale loss and acc to find the average loss/acc per batch\n",
    "    avg_loss = total_loss / total_n\n",
    "    avg_acc = acc_metric.compute().item()\n",
    "    print(f\"Test loss: {avg_loss:.5f} | Test accuracy: {avg_acc * 100:.2f}%\")\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72199cf5",
   "metadata": {},
   "source": [
    "### Model 2: Builing a Convolutional NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3daa4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    \"\"\"\n",
    "    TinyVGG-style CNN for 28x28 Fashion-MNIST.\n",
    "    Uses a dummy forward pass in __init__ to infer Linear in_features.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shade: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int,\n",
    "                 image_size: int = 28):\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(input_shade, hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2)  # 28->14\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2)  # 14->7\n",
    "        )\n",
    "\n",
    "        # --- dummy part: infer flattened features to accelerate/avoid shape bugs ---\n",
    "        with torch.inference_mode():\n",
    "            dummy = torch.zeros(1, input_shade, image_size, image_size)\n",
    "            feat = self.conv_block_2(self.conv_block_1(dummy))\n",
    "            flattened = feat.numel()  # batch=1 so this is channels*H*W\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flattened, hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_units, output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)   # <- removed stray comma that made a tuple\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90104de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_2  = FashionMNISTModelV2(input_shade=1,\n",
    "                               hidden_units=10,\n",
    "                               output_shape=NUM_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f75ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model_2.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=3e-3,                       # try 2e-3 .. 5e-3\n",
    "    epochs=20,                         # total planned epochs\n",
    "    steps_per_epoch=len(train_dataloader),\n",
    "    pct_start=0.3,                     # warmup fraction\n",
    "    div_factor=10,                     # initial lr = max_lr/10\n",
    "    final_div_factor=10                # final lr = max_lr/100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a065fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_loop(history: list,\n",
    "                    model: nn.Module,\n",
    "                    train_data_loader: torch.utils.data.DataLoader,\n",
    "                    test_data_loader: torch.utils.data.DataLoader,\n",
    "                    loss_fn: nn.Module,\n",
    "                    optimizer: torch.optim.Optimizer,\n",
    "                    device: torch.device | str = 'cpu',\n",
    "                    num_classes: int = 10 ,\n",
    "                    scheduler: torch.optim.lr_scheduler._LRScheduler | None  = None,\n",
    "                    epochs: int = 10,\n",
    "                    timer_fn=timer,\n",
    "                    log_path: str | None | Path = None):\n",
    "    \n",
    "    path = Path(log_path) if log_path is not None else Path(\"csv/history_model.csv\")\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cols = [\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"lr\", \"elapsed_s\"]\n",
    "\n",
    "    t0 = timer_fn()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch + 1}\\n-------\" )\n",
    "\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                       data_loader=train_data_loader,\n",
    "                                       loss_fn=loss_fn,\n",
    "                                       optimizer=optimizer,\n",
    "                                       device=device,\n",
    "                                       num_classes=num_classes,\n",
    "                                       scheduler=scheduler)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    data_loader=test_data_loader,\n",
    "                                    device=device,\n",
    "                                    num_classes=num_classes)\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "        else:\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            \n",
    "        row = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\":  train_acc,\n",
    "            \"val_loss\":   test_loss,\n",
    "            \"val_acc\":    test_acc,\n",
    "            \"lr\":         lr,\n",
    "            \"elapsed_s\":  timer_fn() - t0\n",
    "        }\n",
    "        history.append(row)\n",
    "\n",
    "        pd.DataFrame([row], columns=cols).to_csv(\n",
    "            path,\n",
    "            sep= \",\",\n",
    "            mode=\"a\",\n",
    "            header=not path.exists(),\n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "\n",
    "    print(f\"Training finished in {timer_fn() - t0:.2f}s. \"\n",
    "      f\"Logs saved to: {log_path if log_path else {path}}\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0cc3630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from pathlib import Path\\n\\n# --- Training Loop ---\\nhistory = []\\nepochs = 20\\ntrain_start_time = timer()\\n\\n# Create directory for saving results\\nPath(\"csv\").mkdir(parents=True, exist_ok=True)\\n\\nfor epoch in tqdm(range(epochs)):\\n    print(f\"Epoch: {epoch + 1}\\n-------\" )\\n    train_loss, train_acc = train_step(model=model_2,\\n                                       data_loader=train_dataloader,\\n                                       loss_fn=loss_fn,\\n                                       optimizer=optimizer,\\n                                       device=device,\\n                                       num_classes=NUM_CLASSES,\\n                                       scheduler=scheduler)\\n\\n    test_loss, test_acc = test_step(model=model_2,\\n                                    loss_fn=loss_fn,\\n                                    data_loader=test_dataloader,\\n                                    device=device,\\n                                    num_classes=NUM_CLASSES)\\n\\n    lr = optimizer.param_groups[0][\\'lr\\']\\n    history.append({\\n            \"epoch\": epoch,\\n            \"train_loss\": train_loss,\\n            \"train_acc\":  train_acc,\\n            \"val_loss\":   test_loss,\\n            \"val_acc\":    test_acc,\\n            \"lr\":         lr,\\n            \"elapsed_s\":  timer() - train_start_time\\n        })\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from pathlib import Path\n",
    "\n",
    "# --- Training Loop ---\n",
    "history = []\n",
    "epochs = 20\n",
    "train_start_time = timer()\n",
    "\n",
    "# Create directory for saving results\n",
    "Path(\"csv\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch + 1}\\n-------\" )\n",
    "    train_loss, train_acc = train_step(model=model_2,\n",
    "                                       data_loader=train_dataloader,\n",
    "                                       loss_fn=loss_fn,\n",
    "                                       optimizer=optimizer,\n",
    "                                       device=device,\n",
    "                                       num_classes=NUM_CLASSES,\n",
    "                                       scheduler=scheduler)\n",
    "\n",
    "    test_loss, test_acc = test_step(model=model_2,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    data_loader=test_dataloader,\n",
    "                                    device=device,\n",
    "                                    num_classes=NUM_CLASSES)\n",
    "\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    history.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\":  train_acc,\n",
    "            \"val_loss\":   test_loss,\n",
    "            \"val_acc\":    test_acc,\n",
    "            \"lr\":         lr,\n",
    "            \"elapsed_s\":  timer() - train_start_time\n",
    "        })\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bed35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def collecting_preds(model: nn.Module,\n",
    "                     data_loader: torch.utils.data.DataLoader,\n",
    "                     device: torch.device):\n",
    "    model.eval()\n",
    "    y_trues, y_preds = [], []\n",
    "    for X, y in data_loader:\n",
    "        X = X.to(device); y = y.to(device)\n",
    "        logits = model(X)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        y_trues.append(y.cpu())\n",
    "        y_preds.append(preds.cpu())\n",
    "    y_trues = torch.cat(y_trues)\n",
    "    y_preds = torch.cat(y_preds)\n",
    "\n",
    "    return y_trues, y_preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b4d005b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 214.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.17494 | Train accuracy: 56.33% | lr: 0.00048089712487680344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 527.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.81513 | Test accuracy: 69.12%\n",
      "Epoch: 2\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 219.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.76599 | Train accuracy: 71.65% | lr: 0.0009751088405610007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 537.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.64848 | Test accuracy: 76.37%\n",
      "Epoch: 3\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 215.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.67330 | Train accuracy: 74.51% | lr: 0.001650188512315253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 500.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.63413 | Test accuracy: 77.08%\n",
      "Epoch: 4\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 212.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.60303 | Train accuracy: 77.15% | lr: 0.0023252176635719752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 549.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.52701 | Test accuracy: 80.69%\n",
      "Epoch: 5\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 210.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.55129 | Train accuracy: 79.36% | lr: 0.0028192913570417293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 517.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.46001 | Test accuracy: 83.01%\n",
      "Epoch: 6\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 202.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.49992 | Train accuracy: 81.38% | lr: 0.0029999999893649976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 511.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.46547 | Test accuracy: 82.68%\n",
      "Epoch: 7\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 207.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.46526 | Train accuracy: 82.90% | lr: 0.0029627283918257376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 526.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.42645 | Test accuracy: 84.68%\n",
      "Epoch: 8\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 213.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.44404 | Train accuracy: 83.69% | lr: 0.0028528616475330336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 507.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.39235 | Test accuracy: 85.71%\n",
      "Epoch: 9\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 210.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.42336 | Train accuracy: 84.50% | lr: 0.0026759089338092923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 503.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.38438 | Test accuracy: 86.03%\n",
      "Epoch: 10\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 212.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.40688 | Train accuracy: 84.97% | lr: 0.002440743398610807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 531.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.37231 | Test accuracy: 86.84%\n",
      "Epoch: 11\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 210.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.39467 | Train accuracy: 85.63% | lr: 0.0021591572238381872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 525.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.35820 | Test accuracy: 87.05%\n",
      "Epoch: 12\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 209.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.38239 | Train accuracy: 86.07% | lr: 0.001845270316096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 515.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.34426 | Test accuracy: 87.73%\n",
      "Epoch: 13\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 211.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.36624 | Train accuracy: 86.69% | lr: 0.0015148222756160212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 554.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.33936 | Test accuracy: 87.81%\n",
      "Epoch: 14\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 208.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.35525 | Train accuracy: 87.10% | lr: 0.0011843831469787675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 552.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.33212 | Test accuracy: 88.28%\n",
      "Epoch: 15\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 212.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.34691 | Train accuracy: 87.43% | lr: 0.0008705225278877486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 547.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.32095 | Test accuracy: 88.43%\n",
      "Epoch: 16\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 211.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.33708 | Train accuracy: 87.85% | lr: 0.0005889787003519998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 548.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.31943 | Test accuracy: 88.58%\n",
      "Epoch: 17\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 204.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.32976 | Train accuracy: 88.02% | lr: 0.0003538694475088029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 518.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.31404 | Test accuracy: 88.73%\n",
      "Epoch: 18\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 211.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.32329 | Train accuracy: 88.25% | lr: 0.00017698412902646045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 534.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.30766 | Test accuracy: 89.14%\n",
      "Epoch: 19\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 206.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.32083 | Train accuracy: 88.29% | lr: 6.719251338244275e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 544.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.30788 | Test accuracy: 89.09%\n",
      "Epoch: 20\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 207.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.31682 | Train accuracy: 88.49% | lr: 3.0000010635002354e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 526.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.30642 | Test accuracy: 89.14%\n",
      "Training finished in 190.07s. Logs saved to: no log file\n",
      "    epoch  train_loss  train_acc  val_loss  val_acc        lr   elapsed_s\n",
      "17     18    0.323294   0.882533  0.307660   0.8914  0.000177  170.762753\n",
      "18     19    0.320832   0.882933  0.307885   0.8909  0.000067  180.412727\n",
      "19     20    0.316818   0.884850  0.306423   0.8914  0.000030  190.074048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert history to DataFrame and save\n",
    "history = []\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "hist_df = pd.DataFrame(train_test_loop(\n",
    "    history=history,\n",
    "    model=model_2,\n",
    "    train_data_loader=train_dataloader,\n",
    "    test_data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    epochs=epochs,\n",
    "    scheduler=scheduler\n",
    "))\n",
    "print(hist_df.tail(3))           # quick sanity check\n",
    "hist_df.to_csv(\"csv/history_model3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87b3057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class accuracy:\n",
      " 0 T-shirt/top :  85.0%\n",
      " 1 Trouser     :  97.5%\n",
      " 2 Pullover    :  82.2%\n",
      " 3 Dress       :  90.5%\n",
      " 4 Coat        :  87.7%\n",
      " 5 Sandal      :  95.8%\n",
      " 6 Shirt       :  64.2%\n",
      " 7 Sneaker     :  95.8%\n",
      " 8 Bag         :  96.6%\n",
      " 9 Ankle boot  :  96.1%\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top      0.842     0.850     0.846      1000\n",
      "     Trouser      0.988     0.975     0.981      1000\n",
      "    Pullover      0.862     0.822     0.841      1000\n",
      "       Dress      0.879     0.905     0.892      1000\n",
      "        Coat      0.778     0.877     0.825      1000\n",
      "      Sandal      0.981     0.958     0.969      1000\n",
      "       Shirt      0.723     0.642     0.680      1000\n",
      "     Sneaker      0.938     0.958     0.948      1000\n",
      "         Bag      0.967     0.966     0.966      1000\n",
      "  Ankle boot      0.954     0.961     0.958      1000\n",
      "\n",
      "    accuracy                          0.891     10000\n",
      "   macro avg      0.891     0.891     0.891     10000\n",
      "weighted avg      0.891     0.891     0.891     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = collecting_preds(model=model_2,\n",
    "                                  data_loader=test_dataloader,\n",
    "                                  device=device)\n",
    "cm = confusion_matrix(y_true=y_true,\n",
    "                      y_pred=y_pred,\n",
    "                      labels=range(NUM_CLASSES),\n",
    "                      )\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1).clip(min=1)\n",
    "print(\"Per-class accuracy:\")\n",
    "for i, acc in enumerate(per_class_acc):\n",
    "    print(f\"{i:>2} {class_names[i]:<12}: {acc*100:5.1f}%\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c4e976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
