{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8476d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Altuk\\OneDrive\\repos\\skill-builder-process\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics import Accuracy\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "from helper_functions import print_train_time\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from contextlib import nullcontext\n",
    "import torch, torch.backends.cudnn as cudnn, torch.backends.cuda as cuda_bk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fa86fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Altuk\\OneDrive\\repos\\skill-builder-process\\.venv\\Lib\\site-packages\\torch\\backends\\__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:85.)\n",
      "  self.setter(val)\n"
     ]
    }
   ],
   "source": [
    "def pick_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = pick_device()\n",
    "\n",
    "# CUDA-only speed toggles (guard them!)\n",
    "if device.type == \"cuda\":\n",
    "    torch.backends.cudnn.benchmark = True          # good for speed with static shapes\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True   # TF32 fast matmul on Ampere+\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.set_float32_matmul_precision(\"high\")     # prefers fast float32 kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85b43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=2),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "#Setup training data\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform,\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff457849",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "\n",
    "NUM_CLASSES = len(class_names)\n",
    "#Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcddab3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available()\n",
    "                      else \"cuda\" if torch.cuda.is_available()\n",
    "                      else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0c06195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device-aware loader settings\n",
    "if device.type == \"cuda\":\n",
    "    loader_kwargs = dict(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=max(4, os.cpu_count() // 2),\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=2\n",
    "    )\n",
    "elif device.type == \"mps\":\n",
    "    loader_kwargs = dict(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=0,          # multiprocessing not reliable on MPS\n",
    "        pin_memory=False,\n",
    "        persistent_workers=False\n",
    "    )\n",
    "else:  # CPU fallback\n",
    "    loader_kwargs = dict(batch_size=BATCH_SIZE, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b1ab5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(dataset=train_data, shuffle=True, **loader_kwargs)\n",
    "test_dataloader = DataLoader(dataset=test_data, shuffle=True, **loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d7205b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '9')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "774553a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a470e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training func\n",
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device | str = 'cpu',\n",
    "               task: str = \"multiclass\",\n",
    "               num_classes=None,\n",
    "               scheduler: torch.optim.lr_scheduler._LRScheduler | None = None) -> tuple:\n",
    "    \"\"\"Performs one training epoch over data_loader.\"\"\"\n",
    "\n",
    "    # ---- setup ----\n",
    "    if not isinstance(device, torch.device):\n",
    "        device = torch.device(device)\n",
    "    use_cuda = device.type == \"cuda\"\n",
    "    use_mps  = device.type == \"mps\"\n",
    "\n",
    "    model.train()\n",
    "    acc_metric = Accuracy(task=task, num_classes=num_classes).to(device)\n",
    "\n",
    "    # AMP: unified, deprecation-safe\n",
    "    # CUDA: use GradScaler + autocast(\"cuda\", fp16)\n",
    "    # MPS: use autocast(\"mps\", fp16) if available; no scaler\n",
    "    # CPU: no autocast (tiny nets), plain FP32\n",
    "    if use_cuda:\n",
    "        scaler = torch.amp.GradScaler(\"cuda\")  # new API\n",
    "        autocast_cm = torch.amp.autocast(\"cuda\", dtype=torch.float16)\n",
    "    else:\n",
    "        scaler = None\n",
    "        # Try MPS autocast (PyTorch ≥2.5); fallback if not supported\n",
    "        if use_mps:\n",
    "            try:\n",
    "                autocast_cm = torch.amp.autocast(\"mps\", dtype=torch.float16)\n",
    "            except Exception:\n",
    "                autocast_cm = nullcontext()\n",
    "        else:\n",
    "            autocast_cm = nullcontext()\n",
    "\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    total_loss, total_n = 0.0, 0\n",
    "\n",
    "    for X, y in tqdm(data_loader):\n",
    "        non_block = use_cuda  # only helps on CUDA + pinned memory\n",
    "        X = X.to(device, non_blocking=non_block)\n",
    "        y = y.to(device, non_blocking=non_block)\n",
    "\n",
    "        # Channels-last boosts CUDA convs; harmless elsewhere\n",
    "        if use_cuda:\n",
    "            X = X.contiguous(memory_format=torch.channels_last)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast_cm:\n",
    "            logits = model(X)\n",
    "            batch_loss = loss_fn(logits, y)\n",
    "\n",
    "        if scaler is not None:          # CUDA path\n",
    "            scaler.scale(batch_loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:                            # MPS/CPU path\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # metrics/bookkeeping\n",
    "        n = y.size(0)\n",
    "        total_loss += batch_loss.detach().item() * n\n",
    "        total_n    += n\n",
    "        acc_metric.update(logits.detach(), y)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "    avg_loss = total_loss / max(total_n, 1)\n",
    "    avg_acc  = acc_metric.compute().item()\n",
    "    print(f\"Train loss: {avg_loss:.5f} | Train accuracy: {avg_acc*100:.2f}% | lr: {current_lr}\")\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0f04e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing func\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              device: torch.device | str = \"cpu\",\n",
    "              task: str = \"multiclass\",\n",
    "              num_classes=None) -> tuple:\n",
    "    \"\"\"Eval one epoch. Returns (avg_loss, avg_acc).\"\"\"\n",
    "    if not isinstance(device, torch.device):\n",
    "        device = torch.device(device)\n",
    "    use_cuda = device.type == \"cuda\"\n",
    "    use_mps  = device.type == \"mps\"\n",
    "\n",
    "    model.eval()\n",
    "    acc_metric = Accuracy(task=task, num_classes=num_classes).to(device)\n",
    "\n",
    "    # AMP autocast (no GradScaler needed for eval)\n",
    "    if use_cuda:\n",
    "        autocast_cm = torch.amp.autocast(\"cuda\", dtype=torch.float16)\n",
    "    elif use_mps:\n",
    "        # available on recent PyTorch; fallback silently if unsupported\n",
    "        try:\n",
    "            autocast_cm = torch.amp.autocast(\"mps\", dtype=torch.float16)\n",
    "        except Exception:\n",
    "            autocast_cm = nullcontext()\n",
    "    else:\n",
    "        autocast_cm = nullcontext()\n",
    "\n",
    "    total_loss, total_n = 0.0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(data_loader):\n",
    "            non_block = use_cuda  # only helps on CUDA + pinned memory\n",
    "            X = X.to(device, non_blocking=non_block)\n",
    "            y = y.to(device, non_blocking=non_block)\n",
    "\n",
    "            if use_cuda:\n",
    "                X = X.contiguous(memory_format=torch.channels_last)\n",
    "\n",
    "            with autocast_cm:\n",
    "                logits = model(X)\n",
    "                batch_loss = loss_fn(logits, y)\n",
    "\n",
    "            n = y.size(0)\n",
    "            total_loss += batch_loss.detach().item() * n\n",
    "            total_n    += n\n",
    "            acc_metric.update(logits.detach(), y)\n",
    "\n",
    "    avg_loss = total_loss / max(total_n, 1)\n",
    "    avg_acc  = acc_metric.compute().item()\n",
    "    print(f\"Test loss: {avg_loss:.5f} | Test accuracy: {avg_acc*100:.2f}%\")\n",
    "    return avg_loss, avg_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72199cf5",
   "metadata": {},
   "source": [
    "### Model 2: Builing a Convolutional NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3daa4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelV2(nn.Module):\n",
    "    \"\"\"\n",
    "    TinyVGG-style CNN for 28x28 Fashion-MNIST.\n",
    "    Two conv blocks (3x3, ReLU, 3x3, ReLU, MaxPool2d(2)), then MLP head.\n",
    "    Uses same-padding (p=1) so spatial dims are predictable; no dummy pass needed.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shade: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int,\n",
    "                 image_size: int = 28,\n",
    "                 use_channels_last: bool = False,\n",
    "                 init_kaiming: bool = True,\n",
    "                 dropout_p:int = 0.10):\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "        self.use_channels_last = use_channels_last\n",
    "\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(input_shade, hidden_units, kernel_size=3, stride=1, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2)  # 28->14\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, stride=1, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2)  # 14->7\n",
    "        )\n",
    "\n",
    "        # With p=1, stride=1, two pools(2): side = image_size // 4\n",
    "        side = image_size // 4\n",
    "        flattened = hidden_units * side * side\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(flattened, hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_units, output_shape)\n",
    "        )\n",
    "\n",
    "        if init_kaiming:\n",
    "            self._init_weights()\n",
    "\n",
    "        # Optional memory format for faster CUDA convs (harmless elsewhere)\n",
    "        if self.use_channels_last:\n",
    "            self.to(memory_format=torch.channels_last)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, a=math.sqrt(5))\n",
    "                if m.bias is not None:\n",
    "                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n",
    "                    bound = 1 / math.sqrt(fan_in)\n",
    "                    nn.init.uniform_(m.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Make input channels-last if requested (helps on CUDA + AMP)\n",
    "        if self.use_channels_last and x.is_contiguous(memory_format=torch.contiguous_format):\n",
    "            x = x.contiguous(memory_format=torch.channels_last)\n",
    "\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15c6b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelV3(nn.Module):\n",
    "    \"\"\"\n",
    "    TinyVGG-style CNN for 28x28 Fashion-MNIST.\n",
    "    Two conv blocks (3x3, ReLU, 3x3, ReLU, MaxPool2d(2)), then MLP head.\n",
    "    Uses same-padding (p=1) so spatial dims are predictable; no dummy pass needed.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shade: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int,\n",
    "                 image_size: int = 28,\n",
    "                 use_channels_last: bool = False,\n",
    "                 init_kaiming: bool = True,\n",
    "                 dropout_p:int = 0.10):\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "        self.use_channels_last = use_channels_last\n",
    "\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(input_shade, hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2)  # 28->14\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2)  # 14->7\n",
    "        )\n",
    "\n",
    "        # With p=1, stride=1, two pools(2): side = image_size // 4\n",
    "        side = image_size // 4\n",
    "        flattened = hidden_units * side * side\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            #nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(flattened, hidden_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_units, output_shape)\n",
    "        )\n",
    "\n",
    "        if init_kaiming:\n",
    "            self._init_weights()\n",
    "\n",
    "        # Optional memory format for faster CUDA convs (harmless elsewhere)\n",
    "        if self.use_channels_last:\n",
    "            self.to(memory_format=torch.channels_last)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, a=math.sqrt(5))\n",
    "                if m.bias is not None:\n",
    "                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n",
    "                    bound = 1 / math.sqrt(fan_in)\n",
    "                    nn.init.uniform_(m.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Make input channels-last if requested (helps on CUDA + AMP)\n",
    "        if self.use_channels_last and x.is_contiguous(memory_format=torch.contiguous_format):\n",
    "            x = x.contiguous(memory_format=torch.channels_last)\n",
    "\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90104de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_2 = FashionMNISTModelV2(\n",
    "    input_shade=1,\n",
    "    hidden_units=64,            # for your 95% push\n",
    "    output_shape=NUM_CLASSES,\n",
    "    use_channels_last=(device.type == \"cuda\"),\n",
    "    dropout_p=0.10\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65d2c4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313098"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model_2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f75ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model_2.parameters(),\n",
    "    lr=1e-3,              # base lr (will be overridden by OneCycle)\n",
    "    weight_decay=5e-4     # mild regularization, helps generalization\n",
    ")\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=3e-3,                 # peak LR\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=len(train_dataloader),\n",
    "    pct_start=0.3,               # 30% warm-up phase\n",
    "    anneal_strategy='cos',       # smoother decay\n",
    "    div_factor=10,               # initial lr = max_lr / 10\n",
    "    final_div_factor=10          # final lr = max_lr / 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a065fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_loop(history: list,\n",
    "                    model: nn.Module,\n",
    "                    train_data_loader: torch.utils.data.DataLoader,\n",
    "                    test_data_loader: torch.utils.data.DataLoader,\n",
    "                    loss_fn: nn.Module,\n",
    "                    optimizer: torch.optim.Optimizer,\n",
    "                    device: torch.device | str = 'cpu',\n",
    "                    num_classes: int = 10,\n",
    "                    scheduler: torch.optim.lr_scheduler._LRScheduler | None = None,\n",
    "                    epochs: int = 10,\n",
    "                    timer_fn=timer,\n",
    "                    log_path: str | None | Path = None):\n",
    "\n",
    "    # normalize device\n",
    "    if not isinstance(device, torch.device):\n",
    "        device = torch.device(device)\n",
    "\n",
    "    path = Path(log_path) if log_path is not None else Path(\"csv/history_model.csv\")\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cols = [\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"lr\", \"elapsed_s\"]\n",
    "\n",
    "    t0 = timer_fn()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch + 1}\\n-------\")\n",
    "\n",
    "        # train (your train_step already handles AMP/scheduler-per-batch)\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           data_loader=train_data_loader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device,\n",
    "                                           num_classes=num_classes,\n",
    "                                           scheduler=scheduler)\n",
    "\n",
    "        # eval\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        data_loader=test_data_loader,\n",
    "                                        device=device,\n",
    "                                        num_classes=num_classes)\n",
    "\n",
    "        # LR logging (robust to schedulers that don't expose get_last_lr)\n",
    "        try:\n",
    "            lr = scheduler.get_last_lr()[0] if scheduler is not None else optimizer.param_groups[0][\"lr\"]\n",
    "        except Exception:\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        # accurate wall time on CUDA (sync before reading timer)\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        elapsed = timer_fn() - t0\n",
    "\n",
    "        row = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\":  train_acc,\n",
    "            \"val_loss\":   test_loss,\n",
    "            \"val_acc\":    test_acc,\n",
    "            \"lr\":         lr,\n",
    "            \"elapsed_s\":  elapsed\n",
    "        }\n",
    "        history.append(row)\n",
    "\n",
    "        # append one row per epoch\n",
    "        \"\"\"pd.DataFrame([row], columns=cols).to_csv(\n",
    "            path,\n",
    "            sep=\",\",\n",
    "            mode=\"a\",\n",
    "            header=not path.exists(),\n",
    "            index=False\n",
    "        )\"\"\"\n",
    "\n",
    "    # fix the f-string (don’t wrap path in braces)\n",
    "    print(f\"Training finished in {timer_fn() - t0:.2f}s. Logs saved to history. Log after the training is finished\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0cc3630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from pathlib import Path\\n\\n# --- Training Loop ---\\nhistory = []\\nepochs = 20\\ntrain_start_time = timer()\\n\\n# Create directory for saving results\\nPath(\"csv\").mkdir(parents=True, exist_ok=True)\\n\\nfor epoch in tqdm(range(epochs)):\\n    print(f\"Epoch: {epoch + 1}\\n-------\" )\\n    train_loss, train_acc = train_step(model=model_2,\\n                                       data_loader=train_dataloader,\\n                                       loss_fn=loss_fn,\\n                                       optimizer=optimizer,\\n                                       device=device,\\n                                       num_classes=NUM_CLASSES,\\n                                       scheduler=scheduler)\\n\\n    test_loss, test_acc = test_step(model=model_2,\\n                                    loss_fn=loss_fn,\\n                                    data_loader=test_dataloader,\\n                                    device=device,\\n                                    num_classes=NUM_CLASSES)\\n\\n    lr = optimizer.param_groups[0][\\'lr\\']\\n    history.append({\\n            \"epoch\": epoch,\\n            \"train_loss\": train_loss,\\n            \"train_acc\":  train_acc,\\n            \"val_loss\":   test_loss,\\n            \"val_acc\":    test_acc,\\n            \"lr\":         lr,\\n            \"elapsed_s\":  timer() - train_start_time\\n        })\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from pathlib import Path\n",
    "\n",
    "# --- Training Loop ---\n",
    "history = []\n",
    "epochs = 20\n",
    "train_start_time = timer()\n",
    "\n",
    "# Create directory for saving results\n",
    "Path(\"csv\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch + 1}\\n-------\" )\n",
    "    train_loss, train_acc = train_step(model=model_2,\n",
    "                                       data_loader=train_dataloader,\n",
    "                                       loss_fn=loss_fn,\n",
    "                                       optimizer=optimizer,\n",
    "                                       device=device,\n",
    "                                       num_classes=NUM_CLASSES,\n",
    "                                       scheduler=scheduler)\n",
    "\n",
    "    test_loss, test_acc = test_step(model=model_2,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    data_loader=test_dataloader,\n",
    "                                    device=device,\n",
    "                                    num_classes=NUM_CLASSES)\n",
    "\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    history.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\":  train_acc,\n",
    "            \"val_loss\":   test_loss,\n",
    "            \"val_acc\":    test_acc,\n",
    "            \"lr\":         lr,\n",
    "            \"elapsed_s\":  timer() - train_start_time\n",
    "        })\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def collecting_preds(model: nn.Module,\n",
    "                     data_loader: torch.utils.data.DataLoader,\n",
    "                     device: torch.device):\n",
    "    model.eval()\n",
    "    y_trues, y_preds = [], []\n",
    "    for X, y in data_loader:\n",
    "        X = X.to(device); y = y.to(device)\n",
    "        logits = model(X)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        y_trues.append(y.cpu())\n",
    "        y_preds.append(preds.cpu())\n",
    "    y_trues = torch.cat(y_trues)\n",
    "    y_preds = torch.cat(y_preds)\n",
    "\n",
    "    return y_trues, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b4d005b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:29<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.01878 | Train accuracy: 78.01% | lr: 0.000329517422852736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:05<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.84018 | Test accuracy: 85.90%\n",
      "Epoch: 2\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.83496 | Train accuracy: 86.06% | lr: 0.00041677890881558575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 180.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.80170 | Test accuracy: 87.62%\n",
      "Epoch: 3\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.79771 | Train accuracy: 87.63% | lr: 0.0005579685553997742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 164.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.77159 | Test accuracy: 88.89%\n",
      "Epoch: 4\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.76948 | Train accuracy: 88.80% | lr: 0.0007469122077895167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 167.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.75946 | Test accuracy: 88.81%\n",
      "Epoch: 5\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.75433 | Train accuracy: 89.54% | lr: 0.000975347451639734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 171.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.78000 | Test accuracy: 87.99%\n",
      "Epoch: 6\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.74976 | Train accuracy: 89.60% | lr: 0.00123328492445088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 169.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.72816 | Test accuracy: 90.46%\n",
      "Epoch: 7\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.73668 | Train accuracy: 90.38% | lr: 0.0015094451455495708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 164.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.72901 | Test accuracy: 90.60%\n",
      "Epoch: 8\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.72708 | Train accuracy: 90.70% | lr: 0.0017917517623116963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 172.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.72723 | Test accuracy: 90.75%\n",
      "Epoch: 9\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.71978 | Train accuracy: 90.96% | lr: 0.0020678596432097103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 173.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.73667 | Test accuracy: 89.74%\n",
      "Epoch: 10\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.71698 | Train accuracy: 91.05% | lr: 0.0023256947244311103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 178.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.71574 | Test accuracy: 91.12%\n",
      "Epoch: 11\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.71084 | Train accuracy: 91.28% | lr: 0.002553982002837109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 173.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.72016 | Test accuracy: 90.86%\n",
      "Epoch: 12\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.70667 | Train accuracy: 91.42% | lr: 0.0027427385863853203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 165.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.70201 | Test accuracy: 91.23%\n",
      "Epoch: 13\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.70158 | Train accuracy: 91.68% | lr: 0.00288371024116044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 162.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.70168 | Test accuracy: 91.28%\n",
      "Epoch: 14\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.69962 | Train accuracy: 91.84% | lr: 0.0029707323450228426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 149.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.73572 | Test accuracy: 89.99%\n",
      "Epoch: 15\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.69873 | Train accuracy: 91.79% | lr: 0.002999999891676076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 165.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.73392 | Test accuracy: 89.99%\n",
      "Epoch: 16\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.69654 | Train accuracy: 91.87% | lr: 0.0029939708747888974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 163.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.75423 | Test accuracy: 89.79%\n",
      "Epoch: 17\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.69275 | Train accuracy: 91.98% | lr: 0.0029760340540387104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 165.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.77148 | Test accuracy: 86.86%\n",
      "Epoch: 18\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.69273 | Train accuracy: 92.03% | lr: 0.0029463338461595155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 166.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.73689 | Test accuracy: 90.36%\n",
      "Epoch: 19\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.69185 | Train accuracy: 92.03% | lr: 0.0029051093797617168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 151.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.69628 | Test accuracy: 91.46%\n",
      "Epoch: 20\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:17<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.68924 | Train accuracy: 92.21% | lr: 0.0028526925700091553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 165.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.72244 | Test accuracy: 90.45%\n",
      "Training finished in 368.21s. Logs saved to: csv\\history_model.csv\n",
      "    epoch  train_loss  train_acc  val_loss  val_acc        lr   elapsed_s\n",
      "17     18    0.692725   0.920283  0.736888   0.9036  0.002946  332.865091\n",
      "18     19    0.691845   0.920283  0.696282   0.9146  0.002905  350.536524\n",
      "19     20    0.689237   0.922133  0.722437   0.9045  0.002853  368.210482\n",
      "\n",
      "Saved final training history to C:\\Users\\Altuk\\OneDrive\\repos\\skill-builder-process\\ml_basics\\notebooks\\DL\\csv\\history_model3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "history = []\n",
    "EPOCHS = 20\n",
    "\n",
    "# Run train/eval loop\n",
    "train_test_loop(\n",
    "    history=history,\n",
    "    model=model_2,\n",
    "    train_data_loader=train_dataloader,\n",
    "    test_data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    epochs=EPOCHS,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "# Convert once after training (the function already appends per epoch)\n",
    "hist_df = pd.DataFrame(history)\n",
    "\n",
    "# Quick sanity check\n",
    "print(hist_df.tail(3))\n",
    "\n",
    "# Save once at the end (more efficient than re-writing each epoch)\n",
    "out_path = Path(\"csv/history_model3.csv\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "hist_df.to_csv(out_path, index=False)\n",
    "print(f\"\\nSaved final training history to {out_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87b3057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class accuracy:\n",
      " 0 T-shirt/top :  83.7%\n",
      " 1 Trouser     :  97.9%\n",
      " 2 Pullover    :  90.2%\n",
      " 3 Dress       :  91.2%\n",
      " 4 Coat        :  70.0%\n",
      " 5 Sandal      :  94.0%\n",
      " 6 Shirt       :  85.7%\n",
      " 7 Sneaker     :  99.2%\n",
      " 8 Bag         :  98.3%\n",
      " 9 Ankle boot  :  94.1%\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top      0.900     0.837     0.867      1000\n",
      "     Trouser      0.996     0.979     0.987      1000\n",
      "    Pullover      0.872     0.902     0.887      1000\n",
      "       Dress      0.907     0.912     0.909      1000\n",
      "        Coat      0.967     0.700     0.812      1000\n",
      "      Sandal      0.995     0.940     0.967      1000\n",
      "       Shirt      0.648     0.857     0.738      1000\n",
      "     Sneaker      0.902     0.992     0.945      1000\n",
      "         Bag      0.986     0.983     0.984      1000\n",
      "  Ankle boot      0.982     0.941     0.961      1000\n",
      "\n",
      "    accuracy                          0.904     10000\n",
      "   macro avg      0.915     0.904     0.906     10000\n",
      "weighted avg      0.915     0.904     0.906     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = collecting_preds(model=model_2,\n",
    "                                  data_loader=test_dataloader,\n",
    "                                  device=device)\n",
    "cm = confusion_matrix(y_true=y_true,\n",
    "                      y_pred=y_pred,\n",
    "                      labels=range(NUM_CLASSES),\n",
    "                      )\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1).clip(min=1)\n",
    "print(\"Per-class accuracy:\")\n",
    "for i, acc in enumerate(per_class_acc):\n",
    "    print(f\"{i:>2} {class_names[i]:<12}: {acc*100:5.1f}%\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b767e120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "im = ax.imshow(cm, interpolation=\"nearest\")\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"True\")\n",
    "ax.set_xticks(range(NUM_CLASSES)); ax.set_yticks(range(NUM_CLASSES))\n",
    "ax.set_xticklabels(range(NUM_CLASSES)); ax.set_yticklabels(range(NUM_CLASSES))\n",
    "ax.set_title(\"Confusion Matrix (FashionMNIST)\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37465d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 6, 1,  ..., 9, 7, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d43096",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "for i, sample enumerate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c4e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_3 = FashionMNISTModelV3(\n",
    "    input_shade=1,\n",
    "    hidden_units=64,           \n",
    "    output_shape=NUM_CLASSES,\n",
    "    use_channels_last=(device.type == \"cuda\"),\n",
    "    dropout_p=0.10\n",
    ").to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3834a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn3 = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "optimizer3 = torch.optim.Adam(\n",
    "    model_3.parameters(),\n",
    "    lr=1e-3,              # base lr (will be overridden by OneCycle)\n",
    "    weight_decay=5e-4     # mild regularization, helps generalization\n",
    ")\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "scheduler3 = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=3e-3,                 # peak LR\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=len(train_dataloader),\n",
    "    pct_start=0.3,               # 30% warm-up phase\n",
    "    anneal_strategy='cos',       # smoother decay\n",
    "    div_factor=10,               # initial lr = max_lr / 10\n",
    "    final_div_factor=10          # final lr = max_lr / 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e438939b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 82.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.06525 | Train accuracy: 75.36% | lr: 0.00048111662249735246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 159.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.88727 | Test accuracy: 83.65%\n",
      "Epoch: 2\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 87.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.85492 | Train accuracy: 84.86% | lr: 0.0009758691108118561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 163.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.80083 | Test accuracy: 86.93%\n",
      "Epoch: 3\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 88.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.80102 | Train accuracy: 86.98% | lr: 0.001651505021009166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 161.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.77795 | Test accuracy: 87.90%\n",
      "Epoch: 4\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 85.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.77095 | Train accuracy: 88.53% | lr: 0.0023267371025813373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 159.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.75049 | Test accuracy: 89.51%\n",
      "Epoch: 5\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 87.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.75001 | Train accuracy: 89.45% | lr: 0.002820386460689545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 161.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.73765 | Test accuracy: 89.98%\n",
      "Epoch: 6\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 89.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.73983 | Train accuracy: 89.96% | lr: 0.0029999993229755163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 146.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.73888 | Test accuracy: 89.80%\n",
      "Epoch: 7\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 88.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.72798 | Train accuracy: 90.51% | lr: 0.0029624517518538184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 158.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.72760 | Test accuracy: 90.56%\n",
      "Epoch: 8\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 88.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.72388 | Train accuracy: 90.71% | lr: 0.002852322905862015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 160.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.73615 | Test accuracy: 90.33%\n",
      "Epoch: 9\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 85.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.71567 | Train accuracy: 91.02% | lr: 0.0026751351051961503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 156.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.69941 | Test accuracy: 91.45%\n",
      "Epoch: 10\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 88.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.71265 | Train accuracy: 91.04% | lr: 0.0024397732860534306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 158.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.70072 | Test accuracy: 91.66%\n",
      "Epoch: 11\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 87.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.70879 | Train accuracy: 91.37% | lr: 0.00215803947283104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 166.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.69842 | Test accuracy: 91.57%\n",
      "Epoch: 12\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 87.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.70645 | Train accuracy: 91.42% | lr: 0.0018440609753419027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 156.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.69903 | Test accuracy: 91.43%\n",
      "Epoch: 13\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 87.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.69953 | Train accuracy: 91.76% | lr: 0.0015135819865101515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 161.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.69442 | Test accuracy: 91.78%\n",
      "Epoch: 14\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 87.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.69944 | Train accuracy: 91.76% | lr: 0.0011831741027958898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 154.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.70595 | Test accuracy: 91.44%\n",
      "Epoch: 15\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 88.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.69395 | Train accuracy: 92.04% | lr: 0.0008694053551517214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 163.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.69224 | Test accuracy: 91.77%\n",
      "Epoch: 16\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 84.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.69410 | Train accuracy: 91.97% | lr: 0.0005880094187687137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 162.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.68593 | Test accuracy: 92.02%\n",
      "Epoch: 17\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 86.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.69136 | Train accuracy: 92.06% | lr: 0.00035309666090421266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 159.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.68637 | Test accuracy: 92.16%\n",
      "Epoch: 18\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 86.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.69013 | Train accuracy: 92.11% | lr: 0.0001764465881477953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 160.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.68851 | Test accuracy: 92.17%\n",
      "Epoch: 19\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 89.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.68839 | Train accuracy: 92.25% | lr: 6.691717277393429e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 162.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.69145 | Test accuracy: 91.85%\n",
      "Epoch: 20\n",
      "-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 87.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.68664 | Train accuracy: 92.29% | lr: 3.0000677024483493e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 159.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.68701 | Test accuracy: 92.11%\n",
      "Training finished in 59.12s. Logs saved to: csv\\history_model.csv\n",
      "    epoch  train_loss  train_acc  val_loss  val_acc        lr  elapsed_s\n",
      "17     18    0.690134   0.921117  0.688510   0.9217  0.000176  53.277613\n",
      "18     19    0.688386   0.922483  0.691453   0.9185  0.000067  56.162445\n",
      "19     20    0.686637   0.922917  0.687007   0.9211  0.000030  59.116277\n",
      "\n",
      "Saved final training history to C:\\Users\\Altuk\\OneDrive\\repos\\skill-builder-process\\ml_basics\\notebooks\\DL\\csv\\history_model3_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "history = []\n",
    "EPOCHS = 20\n",
    "\n",
    "# Run train/eval loop\n",
    "train_test_loop(\n",
    "    history=history,\n",
    "    model=model_3,\n",
    "    train_data_loader=train_dataloader,\n",
    "    test_data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn3,\n",
    "    optimizer=optimizer3,\n",
    "    device=device,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    epochs=EPOCHS,\n",
    "    scheduler=scheduler3\n",
    ")\n",
    "\n",
    "# Convert once after training (the function already appends per epoch)\n",
    "hist_df = pd.DataFrame(history)\n",
    "\n",
    "# Quick sanity check\n",
    "print(hist_df.tail(3))\n",
    "\n",
    "# Save once at the end (more efficient than re-writing each epoch)\n",
    "out_path = Path(\"csv/history_model3_3.csv\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "hist_df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"\\nSaved final training history to {out_path.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
